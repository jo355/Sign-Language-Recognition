Sign Language Recognition- A sign language recognition project using deep learning and computer vision 

Description: 
Implemented a real-time, static, vision-based approach for identification of the American sign language(ASL) alphabets using deep learning algorithms. Detailed methodology(including architecture diagrams, workflow) explained in the project report along with a review of the previous literature. The CNN (convolutional neural networks) model as well as its pre-trained frameworks, Resnet-34 and EfficientNetB0 were trained and tested on the benchmark datasets, ASL alphabet and HaGRID(Hand gesture recognition dataset). Both frameworks models achieved high accuracy scores of 99.96% and 99.995% while the CNN results of the computer vision based metho were validated in real-time. 

