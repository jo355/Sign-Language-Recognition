{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt \n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbacks import EarlyStopping\n",
    "from CNN_Resnet import CNNModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = tt.Compose([tt.RandomCrop(200, padding=25, padding_mode='reflect'),\n",
    "                         tt.RandomHorizontalFlip(),\n",
    "                         tt.RandomRotation(10),\n",
    "                         tt.RandomPerspective(distortion_scale=0.2),\n",
    "                         tt.ToTensor()\n",
    "                        ])\n",
    "test_tfms = tt.Compose([tt.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".\"\n",
    "dataset = ImageFolder(data_dir+'/asl_alphabet_train/asl_alphabet_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(0.15 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.dataset = copy(dataset)\n",
    "train_ds.dataset.transform = train_tfms\n",
    "val_ds.dataset.transform = test_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(val_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpara = {\n",
    "    'out_features': 29,\n",
    "    'lr': 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = CNNModel(**hyperpara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.train_loader = train_dl\n",
    "tmodel.valid_loader = val_dl\n",
    "\n",
    "MODEL_PATH = \"models/\"\n",
    "MODEL_NAME = \"ResNet\"\n",
    "EPOCHS = 6\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"valid_loss\",\n",
    "    model_path=os.path.join(MODEL_PATH, MODEL_NAME + \"_early.bin\"),\n",
    "    patience=3, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.fit(device=device, epochs=EPOCHS, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.save_model(\"models/final_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Efficient import CNNModel_Eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /Users/gauthamsreekumar/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n",
      "100%|██████████| 20.5M/20.5M [02:51<00:00, 125kB/s] \n"
     ]
    }
   ],
   "source": [
    "efmodel = CNNModel_Eff(**hyperpara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efmodel.train_loader = train_dl\n",
    "efmodel.valid_loader = val_dl\n",
    "\n",
    "MODEL_PATH = \"models/\"\n",
    "MODEL_NAME = \"Efficient\"\n",
    "EPOCHS = 6\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"valid_loss\",\n",
    "    model_path=os.path.join(MODEL_PATH, MODEL_NAME + \"_early.bin\"),\n",
    "    patience=3, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efmodel.fit(device=device, epochs=EPOCHS, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.save_model(\"models/final_eff.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d4ea69a21a859c03a8ed5a60733ff43082e326d6e4e222aa2d89b70b07ef97c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
